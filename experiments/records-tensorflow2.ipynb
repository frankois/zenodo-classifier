{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sklearn\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./zenodo_open_metadata_06_04_2017.json\", \"r\") as fp:\n",
    "    data = json.load(fp)\n",
    "spams = [17229, 400865, 19031, 285825, 440002, 292995, 221828, 18818, 160518, 32519, 437895, 22211, 290571, 438157, 44942, 33550, 246800, 51728, 398866, 400531, 60051, 50704, 32918, 164886, 164888, 495001, 165784, 34331, 321818, 60828, 346531, 399268, 18045, 27942, 35364, 30632, 202291, 47155, 293045, 47286, 290359, 224947, 29113, 375738, 20539, 17596, 293053, 439998, 439997, 290237, 49089, 440001, 440003, 440004, 440005, 440006, 440007, 154696, 440009, 440008, 290123, 35276, 284358, 398797, 32076, 33365, 249942, 290134, 344537, 166752, 291812, 18281, 46445, 51054, 290685, 34287, 28271, 439999, 232944, 290157, 23155, 290166, 440000, 249981]\n",
    "maybe_spams = [153959, 12846, 13138, 13385, 398764, 400012]\n",
    "for d in data:\n",
    "    if d['recid'] in (spams + maybe_spams):\n",
    "        d['spam'] = True\n",
    "labels = [d['spam'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feat_tr(d):\n",
    "    return d['description'] + d['title']\n",
    "\n",
    "X = [feat_tr(d) for d in data]\n",
    "y = [d['spam'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngram_range=(1, 1)\n",
    "count_vect = CountVectorizer(ngram_range=ngram_range, max_features=5000)\n",
    "tfid = TfidfTransformer()\n",
    "X_v = count_vect.fit_transform(X)\n",
    "X_v = tfid.fit_transform(X_v)\n",
    "trainX, testX, trainY, testY = train_test_split(X_v, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX_v = np.asarray(trainX.todense())\n",
    "trainY_v = np.array([float(y) for y in trainY])\n",
    "testX_v = np.asarray(testX.todense())\n",
    "testY_v = np.array([float(y) for y in testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpf0s_0rem\n",
      "INFO:tensorflow:Using config: {'_save_summary_steps': 100, '_num_ps_replicas': 0, '_environment': 'local', '_save_checkpoints_steps': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f294395bf98>, '_num_worker_replicas': 0, '_save_checkpoints_secs': 600, '_tf_random_seed': None, '_model_dir': '/tmp/tmpf0s_0rem', '_keep_checkpoint_every_n_hours': 10000, '_task_id': 0, '_master': '', '_task_type': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_evaluation_master': '', '_is_chief': True, '_session_config': None}\n",
      "WARNING:tensorflow:From /home/alice/env/zenodo/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpf0s_0rem/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 0.693146\n",
      "INFO:tensorflow:global_step/sec: 19.2649\n",
      "INFO:tensorflow:step = 101, loss = 0.178509 (5.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.1864\n",
      "INFO:tensorflow:step = 201, loss = 0.108977 (4.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.0248\n",
      "INFO:tensorflow:step = 301, loss = 0.0987505 (5.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8446\n",
      "INFO:tensorflow:step = 401, loss = 0.0931283 (7.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8692\n",
      "INFO:tensorflow:step = 501, loss = 0.098127 (5.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.5197\n",
      "INFO:tensorflow:step = 601, loss = 0.112075 (4.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8893\n",
      "INFO:tensorflow:step = 701, loss = 0.0771129 (6.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.4322\n",
      "INFO:tensorflow:step = 801, loss = 0.079082 (6.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.7484\n",
      "INFO:tensorflow:step = 901, loss = 0.0689232 (5.064 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpf0s_0rem/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0814617.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._BinaryLogisticHead object at 0x7f2943ef7978>, 'feature_columns': [_RealValuedColumn(column_name='x', dimension=5000, default_value=None, dtype=tf.float32, normalizer=None)], 'joint_weights': False, 'optimizer': None, 'gradient_clip_norm': None})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# NumPy is often used to load, manipulate and preprocess data.\n",
    "import numpy as np\n",
    "\n",
    "# Declare list of features. We only have one real-valued feature. There are many\n",
    "# other types of columns that are more complicated and useful.\n",
    "features = [tf.contrib.layers.real_valued_column(\"x\", dimension=trainX_v.shape[1])]\n",
    "\n",
    "# An estimator is the front end to invoke training (fitting) and evaluation\n",
    "# (inference). There are many predefined types like linear regression,\n",
    "# logistic regression, linear classification, logistic classification, and\n",
    "# many neural network classifiers and regressors. The following code\n",
    "# provides an estimator that does linear regression.\n",
    "estimator = tf.contrib.learn.LinearClassifier(feature_columns=features)\n",
    "\n",
    "# TensorFlow provides many helper methods to read and set up data sets.\n",
    "# Here we use `numpy_input_fn`. We have to tell the function how many batches\n",
    "# of data (num_epochs) we want and how big each batch should be.\n",
    "#x = np.array([1., 2., 3., 4.])\n",
    "#y = np.array([0., -1., -2., -3.])\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":trainX_v}, trainY_v, batch_size=1000,\n",
    "                                              num_epochs=10)\n",
    "\n",
    "# We can invoke 1000 training steps by invoking the `fit` method and passing the\n",
    "# training data set.\n",
    "estimator.fit(input_fn=input_fn, steps=1000)\n",
    "\n",
    "# Here we evaluate how well our model did. In a real example, we would want\n",
    "# to use a separate validation and testing data set to avoid overfitting.\n",
    "#print(estimator.evaluate(input_fn=input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":trainX_v}, trainY_v, batch_size=500,\n",
    "                                              num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alice/env/zenodo/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpfu2i5chz/model.ckpt-2000\n",
      "INFO:tensorflow:Saving checkpoints for 2001 into /tmp/tmpfu2i5chz/model.ckpt.\n",
      "INFO:tensorflow:step = 2001, loss = 0.0651012\n",
      "INFO:tensorflow:global_step/sec: 44.109\n",
      "INFO:tensorflow:step = 2101, loss = 0.0665069 (2.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.1782\n",
      "INFO:tensorflow:step = 2201, loss = 0.0592572 (2.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.169\n",
      "INFO:tensorflow:step = 2301, loss = 0.0522081 (2.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.84\n",
      "INFO:tensorflow:step = 2401, loss = 0.0323073 (2.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.3927\n",
      "INFO:tensorflow:step = 2501, loss = 0.0359555 (2.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.4483\n",
      "INFO:tensorflow:step = 2601, loss = 0.0468552 (2.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.4038\n",
      "INFO:tensorflow:step = 2701, loss = 0.0372016 (2.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.5463\n",
      "INFO:tensorflow:step = 2801, loss = 0.036417 (2.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0832\n",
      "INFO:tensorflow:step = 2901, loss = 0.060313 (3.023 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into /tmp/tmpfu2i5chz/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0434444.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._BinaryLogisticHead object at 0x7f29429555f8>, 'feature_columns': [_RealValuedColumn(column_name='x', dimension=5000, default_value=None, dtype=tf.float32, normalizer=None)], 'joint_weights': False, 'optimizer': None, 'gradient_clip_norm': None})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(input_fn=input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_fn_test = tf.contrib.learn.io.numpy_input_fn({\"x\":testX_v}, batch_size=testX_v.shape[0],\n",
    "                                              num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alice/env/zenodo/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py:347: calling LinearClassifier.predict (from tensorflow.contrib.learn.python.learn.estimators.linear) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_classes, or set `outputs` argument.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpfu2i5chz/model.ckpt-3000\n",
      "Counter({(False, False): 57653, (True, False): 1846, (False, True): 1192, (True, True): 29})\n",
      "Spam->Spam: 0.0155\n",
      "Ham -> Ham: 0.9797\n"
     ]
    }
   ],
   "source": [
    "y_out = estimator.predict(input_fn=input_fn_test)\n",
    "y_out = np.array(list(y_out))\n",
    "y_out2 = list(y_out > 0.5)\n",
    "acc = [(ref, pred) for ref, pred in zip(testY, y_out2)]\n",
    "c = Counter(acc)\n",
    "print(c)\n",
    "print(\"Spam->Spam: {0:.4f}\".format(c[(True, True)] / (c[(True, True)] + c[(True, False)])))\n",
    "print(\"Ham -> Ham: {0:.4f}\".format(c[(False, False)] / (c[(False, False)] + c[(False, True)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpnbcll3pl\n",
      "INFO:tensorflow:Using config: {'_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_model_dir': '/tmp/tmpnbcll3pl', '_save_checkpoints_secs': 600, '_environment': 'local', '_num_ps_replicas': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f70be88fdd8>, '_master': '', '_task_type': None, '_task_id': 0, '_is_chief': True, '_keep_checkpoint_max': 5, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_save_checkpoints_steps': None, '_num_worker_replicas': 0, '_save_summary_steps': 100}\n",
      "WARNING:tensorflow:From /home/alice/env/zenodo/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpnbcll3pl/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 2.5\n",
      "INFO:tensorflow:global_step/sec: 717.143\n",
      "INFO:tensorflow:step = 101, loss = 0.0311754 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 733.201\n",
      "INFO:tensorflow:step = 201, loss = 0.00591622 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 790.352\n",
      "INFO:tensorflow:step = 301, loss = 0.00069205 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 777.754\n",
      "INFO:tensorflow:step = 401, loss = 0.000183097 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 631.954\n",
      "INFO:tensorflow:step = 501, loss = 1.86037e-05 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.479\n",
      "INFO:tensorflow:step = 601, loss = 5.12256e-06 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 1048.02\n",
      "INFO:tensorflow:step = 701, loss = 5.85362e-07 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 951.985\n",
      "INFO:tensorflow:step = 801, loss = 1.03556e-07 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 1269.5\n",
      "INFO:tensorflow:step = 901, loss = 1.34917e-08 (0.079 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpnbcll3pl/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.2748e-09.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegressor(params={'optimizer': None, 'head': <tensorflow.contrib.learn.python.learn.estimators.head._RegressionHead object at 0x7f703c6430f0>, 'gradient_clip_norm': None, 'joint_weights': False, 'feature_columns': [_RealValuedColumn(column_name='x', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)]})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# NumPy is often used to load, manipulate and preprocess data.\n",
    "import numpy as np\n",
    "\n",
    "# Declare list of features. We only have one real-valued feature. There are many\n",
    "# other types of columns that are more complicated and useful.\n",
    "features = [tf.contrib.layers.real_valued_column(\"x\", dimension=1)]\n",
    "\n",
    "# An estimator is the front end to invoke training (fitting) and evaluation\n",
    "# (inference). There are many predefined types like linear regression,\n",
    "# logistic regression, linear classification, logistic classification, and\n",
    "# many neural network classifiers and regressors. The following code\n",
    "# provides an estimator that does linear regression.\n",
    "estimator = tf.contrib.learn.LinearRegressor(feature_columns=features)\n",
    "\n",
    "# TensorFlow provides many helper methods to read and set up data sets.\n",
    "# Here we use `numpy_input_fn`. We have to tell the function how many batches\n",
    "# of data (num_epochs) we want and how big each batch should be.\n",
    "x = np.array([1., 2., 3., 4.])\n",
    "y = np.array([0., -1., -2., -3.])\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":x}, y, batch_size=4,\n",
    "                                              num_epochs=1000)\n",
    "\n",
    "# We can invoke 1000 training steps by invoking the `fit` method and passing the\n",
    "# training data set.\n",
    "estimator.fit(input_fn=input_fn, steps=1000)\n",
    "\n",
    "# Here we evaluate how well our model did. In a real example, we would want\n",
    "# to use a separate validation and testing data set to avoid overfitting.\n",
    "#print(estimator.evaluate(input_fn=input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x2 = np.array([2., 3., 5., 4.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":x2}, batch_size=4,\n",
    "                                              num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alice/env/zenodo/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py:347: calling LinearRegressor.predict (from tensorflow.contrib.learn.python.learn.estimators.linear) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_scores, or set `outputs` argument.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpnbcll3pl/model.ckpt-1000\n"
     ]
    }
   ],
   "source": [
    "y2 = list(estimator.predict(input_fn=input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.000056, -3.9998956, -2.999949, -2.0000024]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Zenodo",
   "language": "python",
   "name": "zenodo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
